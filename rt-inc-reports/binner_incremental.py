#!/usr/bin/python
# -*- coding: utf-8 -*-
#########################################################
# binner_incremental.py
# 07/09/2015 created; 8/8/2017 updated; 1/17/2018 updated encoding header
#
########################################################

'''
   read in an RT dump file, and generate "binner" plots
   comparable to the onces generated by running the older
   "aggregator/binner" python scripts, and generating graphs
   by hand in excel.

   This 2nd major version takes as input the pickled Pandas
   dataframe generated by
       aggregator_data.py

   USAGE: $ python binner_incremental.py picklefilpath
          where picklefilepath is a pointer to the pickled file.
   Ex.,(MS Windows example) 
   $ python binner_incremental.py "c:\Users\bhecker\RT-reports\data\pickled-merged_2015-07-10T145241.pkl"
   
   INPUTS: pickled version of aggregator_data.py output
   
   OUTPUT: binner plots imputing queue size over time, plus a
        index.html page in the same directory, for ease of browsing.

   EXAMPLES OF OUTPUT: http://www.slac.stanford.edu/~bhecker/RT_metrics/2015-*_analyses/ 

'''
################################################################
# FIXME AND IMPROVEMENTS
#
# * output the date of the extract / date of last data point - 
#     analysis won't always run in the same time frame as the extract
################################################################


def generate_index_page(starttime, queuelist):
    pageCode='<html><head><title>RT bin graphs, generated %s</title> </head>\n' % starttime
    pageCode += '<body><h1>RT bin graphs</h1>\n'
    pageCode += '<body><h3>generated %s </h3>\n' % starttime
    pageCode += '<ol>'
    for q in queuelist:
        pageCode += '<li><a href="'+q+'.png">'+q+'</a></li>\n'
    pageCode += '</ol></body></html>'
    return(pageCode)

def readPickle(infile):
    import cPickle
    newDF = cPickle.load(open(infile, 'rb'))
    return(newDF)

import pandas as pd;
import numpy as np;
import matplotlib as mpl;
## next line must occur before any mpl etc commands or imports
#mpl.use("Qt4Agg")

import matplotlib.pyplot as plt;
import datetime, os, sys; 

## directory for data file  input and output
PICKLEFILEPATH = sys.argv[1]
# pickfile may be Unix or Windows
if "\\" in PICKLEFILEPATH:
    #windows
    FILEPATH, PICKLEFILE = PICKLEFILEPATH.split('\\data\\')
else:
    #unix
    FILEPATH, PICKLEFILE = PICKLEFILEPATH.split('/data/')
    
print "FILEPATH=", FILEPATH
print "PICKLEFILE=", PICKLEFILE
 
STARTTIME = datetime.datetime.today().isoformat()[0:-7]
print "Start time:", STARTTIME
print "Display mode:", plt.matplotlib.rcParams['backend']

##queues of interest
QueueList = [ 'Authors','AUTHORS_add_user', 'AUTHORS_claim_manual',\
              'AUTHORS_cor_user',\
              'CONF_add+cor', 'CONF_add_user', 'Feedback',\
              'HEP', 'HEP_add_user', 'HEP_cor_user', 'HEP_ref_user', \
              'HEP_curation', 'Inspire-References', 'INST_add+cor', \
              'JOBS','HEP_publishing']

#QueueList = ['AUTHORS_cor_user']

## unpickle entireSheetQI
entireSheetQI = readPickle(PICKLEFILEPATH)

## modern epoch, i.e., point at which analysis starts being meaningful
BIN_START_EPOCH = pd.datetime(2013, 5, 1)  

#define weekly range to be used in defining binning dataframes.
rng = pd.date_range(start=BIN_START_EPOCH, end=datetime.date.today(), freq='w')

### create output directory for graphs
pathx = FILEPATH + '\\graphs\\' + 'binner-'+STARTTIME.replace(':','')

## odd structure, but avoids race condition and avoids file/dir confusion
try: 
    os.makedirs(pathx)
except OSError:
    if not os.path.isdir(pathx):
        raise

####################################
## do the counting

for thisQueueName in QueueList:
    # extract only rows that belong to the selected queue
    ThisQueueFrame = entireSheetQI.loc[thisQueueName]
    print "===> ",thisQueueName,"<========="
    ## I didn't see a way to extract the ID column if it was the index
    qFrame = ThisQueueFrame.reset_index()
    idKeys = qFrame['id']
    # set up fresh bin (Pandas dataframe)
    tsbin = pd.Series(0, index=rng)
    qFrame = qFrame.set_index('id')

    for k in idKeys:
        c = qFrame.loc[k]['Created']
        y, m, d = c[:10].split('-')
        c = pd.datetime(int(y),int(m),int(d) ) 
        r = qFrame.loc[k]['Resolved'] 
        if r == "Not set": 
            r = pd.datetime(2020, 12, 31)
        else:
            y, m, d = r[:10].split('-')
            r = pd.datetime(int(y), int(m), int(d) )
            
        ############################################################################
        ## inconsistency between RT and binner: RT counts tickets which are
        ##    open, but have a Resolved date, as "open". Binner would natively
        ##    count these as resolved. So binner current counts would be < RT.
        ##    This check makes binner counting more like RT, by setting the
        ##    Resolved date to the "not set" date if status is open |new |stalled.
        if qFrame.loc[k]['Status'] in ['open','new', 'stalled']:
            r = pd.datetime(2020, 12, 31)


        for beginBin in tsbin.index:
            ## bin is an entire week -- careful comparison
            ## Created is before or equal to "endBin" date, 
            ## and Resolved is on or after the beginBin date.
            ## This way tix crated and resolved in same week get counted.

            if c <= beginBin+datetime.timedelta(days=6) and r >= beginBin:
                tsbin.loc[beginBin] += 1

    ##print "tsbin tail/head", tsbin.head(), tsbin.tail()

    ## plot ##############

    #get_ipython().magic(u'matplotlib inline')
    #print plt.matplotlib.rcParams['backend']
    plt.figure();

    plt.ylabel("number of unresolved tickets"); 
    plt.title(thisQueueName + " Queue Size")
    tsbin.plot(kind='line')
    #next line forces the y axis to originate at zero
    plt.ylim(0,)

    # how to make the directory stick for saving the image??

    plt.savefig(pathx+'\\'+thisQueueName+'.png', dpi=140, facecolor='w', format='png')
    plt.close()

OUTX = open(pathx+'\\nbm-index.html','w')
OUTX.write(generate_index_page(STARTTIME, QueueList ) )
OUTX.close()

print "End time:", datetime.datetime.today().isoformat()
